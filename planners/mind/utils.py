import torch
import copy
import numpy as np
from typing import List, Any, Dict
from shapely.geometry import LineString
from av2.map.lane_segment import LaneType, LaneMarkType
from av2.datasets.motion_forecasting.data_schema import ObjectType

def gpu(data, device):
    """
    Transfer tensor in `data` to gpu recursively
    `data` can be dict, list or tuple
    """
    if isinstance(data, list) or isinstance(data, tuple):
        data = [gpu(x, device=device) for x in data]
    elif isinstance(data, dict):
        data = {key: gpu(_data, device=device) for key, _data in data.items()}
    elif isinstance(data, torch.Tensor):
        data = data.contiguous().to(device, non_blocking=True)
    return data



def from_numpy(data):
    """Recursively transform numpy.ndarray to torch.Tensor.
    """
    if isinstance(data, dict):
        for key in data.keys():
            data[key] = from_numpy(data[key])
    if isinstance(data, list) or isinstance(data, tuple):
        data = [from_numpy(x) for x in data]
    if isinstance(data, np.ndarray):
        """Pytorch now has bool type."""
        data = torch.from_numpy(data)
    return data


def padding_traj_nn(traj):
    n = len(traj)
    # forward
    buff = None
    for i in range(n):
        if np.all(buff == None) and np.all(traj[i] != None):
            buff = traj[i]
        if np.all(buff != None) and np.all(traj[i] == None):
            traj[i] = buff
        if np.all(buff != None) and np.all(traj[i] != None):
            buff = traj[i]
    # backward
    buff = None
    for i in reversed(range(n)):
        if np.all(buff == None) and np.all(traj[i] != None):
            buff = traj[i]
        if np.all(buff != None) and np.all(traj[i] == None):
            traj[i] = buff
        if np.all(buff != None) and np.all(traj[i] != None):
            buff = traj[i]
    return traj


def tgt_gather(batch_size, tgt_nodes_list, tgt_rpe_list):
    tgt_nodes_feat = []
    tgt_rpe_feat = []
    # ~ calc tgt feat
    for tgt_nodes, tgt_rpe in zip(tgt_nodes_list, tgt_rpe_list):
        tgt_nodes_feat.append(tgt_nodes)
        tgt_rpe_feat.append(tgt_rpe)

    tgt_nodes_feat = torch.stack(tgt_nodes_feat, dim=0)
    tgt_rpe_feat = torch.stack(tgt_rpe_feat, dim=0).reshape(batch_size, -1)
    return tgt_nodes_feat, tgt_rpe_feat


def graph_gather(batch_size, graphs):
    '''
        graphs[i]
            node_ctrs           torch.Size([116, N_{pt}, 2])
            node_vecs           torch.Size([116, N_{pt}, 2])
            intersect           torch.Size([116, N_{pt}])
            lane_type           torch.Size([116, N_{pt}, 3])
            cross_left          torch.Size([116, N_{pt}, 3])
            cross_right         torch.Size([116, N_{pt}, 3])
            left                torch.Size([116, N_{pt}])
            right               torch.Size([116, N_{pt}])
            lane_ctrs           torch.Size([116, 2])
            lane_vecs           torch.Size([116, 2])
            num_nodes           1160
            num_lanes           116
    '''
    lane_idcs = list()
    lane_count = 0
    for i in range(batch_size):
        l_idcs = torch.arange(lane_count, lane_count + graphs[i]["num_lanes"])
        lane_idcs.append(l_idcs)
        lane_count = lane_count + graphs[i]["num_lanes"]

    graph = dict()
    for key in ["node_ctrs", "node_vecs", "intersect", "lane_type", "cross_left", "cross_right", "left", "right"]:
        graph[key] = torch.cat([x[key] for x in graphs], 0)
    for key in ["lane_ctrs", "lane_vecs"]:
        graph[key] = [x[key] for x in graphs]

    lanes = torch.cat([graph['node_ctrs'],
                       graph['node_vecs'],
                       graph['intersect'].unsqueeze(2),
                       graph['lane_type'],
                       graph['cross_left'],
                       graph['cross_right'],
                       graph['left'].unsqueeze(2),
                       graph['right'].unsqueeze(2)], dim=-1)  # [N_{lane}, 9, F]
    return lanes, lane_idcs


def actor_gather(batch_size, trajs):
    num_actors = [len(x['TRAJS_CTRS']) for x in trajs]

    act_feats = []
    for i in range(batch_size):
        traj_pos = trajs[i]['TRAJS_POS_OBS']
        traj_disp = torch.zeros_like(traj_pos)
        traj_disp[:, 1:, :] = traj_pos[:, 1:, :] - traj_pos[:, :-1, :]

        act_feat = torch.cat([traj_disp,
                              trajs[i]['TRAJS_ANG_OBS'],
                              trajs[i]['TRAJS_VEL_OBS'],
                              trajs[i]['TRAJS_TYPE'],
                              trajs[i]['PAD_OBS'].unsqueeze(-1)], dim=-1)
        act_feats.append(act_feat)

    act_feats = [x.transpose(1, 2) for x in act_feats]
    actors = torch.cat(act_feats, 0)  # [N_a, feat_len, 50], N_a is agent number in a batch
    actors = actors[..., 2:]  # ! tmp solution
    actor_idcs = []  # e.g. [tensor([0, 1, 2, 3]), tensor([ 4,  5,  6,  7,  8,  9, 10])]
    count = 0
    for i in range(batch_size):
        idcs = torch.arange(count, count + num_actors[i])
        actor_idcs.append(idcs)
        count += num_actors[i]
    return actors, actor_idcs


def collate_fn(batch: List[Any]) -> Dict[str, Any]:
    if len(batch) == 0:
        return None
    batch = from_numpy(batch)
    data = dict()
    data['BATCH_SIZE'] = len(batch)
    # Batching by use a list for non-fixed size
    for key in batch[0].keys():
        data[key] = [x[key] for x in batch]
    '''
        Keys:
        'BATCH_SIZE',
        'ORIG', 'ROT',
        'TRAJS', 'LANE_GRAPH', 'RPE'
    '''

    actors, actor_idcs = actor_gather(data['BATCH_SIZE'], data['TRAJS'])
    lanes, lane_idcs = graph_gather(data['BATCH_SIZE'], data["LANE_GRAPH"])
    tgt_nodes, tgt_rpe = tgt_gather(data['BATCH_SIZE'], data['TGT_NODES'], data['TGT_RPE'])

    data['ACTORS'] = actors
    data['ACTOR_IDCS'] = actor_idcs
    data['LANES'] = lanes
    data['LANE_IDCS'] = lane_idcs
    data['TGT_NODES'] = tgt_nodes
    data['TGT_RPE'] = tgt_rpe
    return data


def get_new_lane_graph(lane_graph, orig, rot, device):
    ret_lane_graph = gpu(copy.deepcopy(lane_graph), device=device)
    # transform the lane_ctrs and lane_vecs
    ret_lane_graph['lane_ctrs'] = torch.matmul(ret_lane_graph['lane_ctrs'] - orig, rot)
    ret_lane_graph['lane_vecs'] = torch.matmul(ret_lane_graph['lane_vecs'], rot)

    return ret_lane_graph


def get_origin_rotation(traj_pos, traj_ang, device):
    obs_len = 50
    orig = traj_pos[obs_len - 1]
    theta = traj_ang[obs_len - 1]
    if isinstance(orig, torch.Tensor):
        rot = torch.tensor([[torch.cos(theta), -torch.sin(theta)],
                            [torch.sin(theta), torch.cos(theta)]]).to(device)
    elif isinstance(orig, np.ndarray):
        rot = np.array([[np.cos(theta), -np.sin(theta)],
                        [np.sin(theta), np.cos(theta)]])
    return orig, rot, theta


def get_rpe(ctrs, vecs, radius=100.0):
    # distance encoding
    d_pos = (ctrs.unsqueeze(0) - ctrs.unsqueeze(1)).norm(dim=-1)
    mask = None
    d_pos = d_pos * 2 / radius  # scale [0, radius] to [0, 2]
    pos_rpe = d_pos.unsqueeze(0)

    # angle diff
    cos_a1 = get_cos(vecs.unsqueeze(0), vecs.unsqueeze(1))
    sin_a1 = get_sin(vecs.unsqueeze(0), vecs.unsqueeze(1))
    # print('cos_a1: ', cos_a1.shape, 'sin_a1: ', sin_a1.shape)

    v_pos = ctrs.unsqueeze(0) - ctrs.unsqueeze(1)
    cos_a2 = get_cos(vecs.unsqueeze(0), v_pos)
    sin_a2 = get_sin(vecs.unsqueeze(0), v_pos)
    # print('cos_a2: ', cos_a2.shape, 'sin_a2: ', sin_a2.shape)

    ang_rpe = torch.stack([cos_a1, sin_a1, cos_a2, sin_a2])
    rpe = torch.cat([ang_rpe, pos_rpe], dim=0)
    return rpe, mask


def get_angle(vel):
    return torch.atan2(vel[..., 1], vel[..., 0])


def get_cos(v1, v2):
    ''' input: [M, N, 2], [M, N, 2]
        output: [M, N]
        cos(<a,b>) = (a dot b) / |a||b|
    '''
    v1_norm = v1.norm(dim=-1)
    v2_norm = v2.norm(dim=-1)
    v1_x, v1_y = v1[..., 0], v1[..., 1]
    v2_x, v2_y = v2[..., 0], v2[..., 1]
    cos_dang = (v1_x * v2_x + v1_y * v2_y) / (v1_norm * v2_norm + 1e-10)
    return cos_dang


def get_sin(v1, v2):
    ''' input: [M, N, 2], [M, N, 2]
        output: [M, N]
        sin(<a,b>) = (a x b) / |a||b|
    '''
    v1_norm = v1.norm(dim=-1)
    v2_norm = v2.norm(dim=-1)
    v1_x, v1_y = v1[..., 0], v1[..., 1]
    v2_x, v2_y = v2[..., 0], v2[..., 1]
    sin_dang = (v1_x * v2_y - v1_y * v2_x) / (v1_norm * v2_norm + 1e-10)
    return sin_dang


def get_agent_trajectories(agent_obs, device):
    obs_len = 50

    # * find idcs
    av_idx = None
    exo_idcs = list()  # exclude AV
    key_list = []
    for idx, key in enumerate(agent_obs.keys()):
        if key == 'AV':
            av_idx = idx
        else:
            exo_idcs.append(idx)
        key_list.append(key)

    sorted_idcs = [av_idx] + exo_idcs
    sorted_cat = ["av"] + ["exo"] * len(exo_idcs)
    sorted_tid = [key_list[idx] for idx in sorted_idcs]

    # * get timesteps and timesteps
    ts = np.arange(0, obs_len)  # [0, 1,..., 49]
    ts_obs = ts[obs_len - 1]  # always 49

    # * must follows the pre-defined order
    trajs_pos, trajs_ang, trajs_vel, trajs_type, has_flags = list(), list(), list(), list(), list()
    trajs_tid, trajs_cat = list(), list()  # track id and category
    for k, ind in enumerate(sorted_idcs):
        key = key_list[ind]
        track = agent_obs[key]

        # * pass if no observation at the last timestep
        if track.object_states[-1].observed is False:
            continue

        # * get traj
        observed_flag = np.array([1 if s.observed else 0 for s in track.object_states])

        traj_ts = np.arange(obs_len - len(track.object_states), obs_len)
        traj_ts = traj_ts[observed_flag == 1]

        traj_pos = np.array(
            [list(x.position) if x.observed else [0.0, 0.0] for x in track.object_states])  # [N_{frames}, 2]
        traj_pos = traj_pos[observed_flag == 1]
        traj_ang = np.array([x.heading if x.observed else 0.0 for x in track.object_states])  # [N_{frames}]
        traj_ang = traj_ang[observed_flag == 1]
        traj_vel = np.array(
            [list(x.velocity) if x.observed else [0.0, 0.0] for x in track.object_states])  # [N_{frames}, 2]
        traj_vel = traj_vel[observed_flag == 1]

        # print(has_flag.shape, traj_ts.shape, traj_ts)
        has_flag = np.zeros_like(ts)
        has_flag[traj_ts] = 1
        # object type
        obj_type = np.zeros(7)  # 7 types
        if track.object_type == ObjectType.VEHICLE:
            obj_type[0] = 1
        elif track.object_type == ObjectType.PEDESTRIAN:
            obj_type[1] = 1
        elif track.object_type == ObjectType.MOTORCYCLIST:
            obj_type[2] = 1
        elif track.object_type == ObjectType.CYCLIST:
            obj_type[3] = 1
        elif track.object_type == ObjectType.BUS:
            obj_type[4] = 1
        elif track.object_type == ObjectType.UNKNOWN:
            obj_type[5] = 1
        else:
            obj_type[6] = 1  # for all static objects
        traj_type = np.zeros((len(ts), 7))
        traj_type[traj_ts] = obj_type

        # pad pos, nearest neighbor
        traj_pos_pad = np.full((len(ts), 2), None)
        traj_pos_pad[traj_ts] = traj_pos
        traj_pos_pad = padding_traj_nn(traj_pos_pad)
        # pad ang, nearest neighbor
        traj_ang_pad = np.full(len(ts), None)
        traj_ang_pad[traj_ts] = traj_ang
        traj_ang_pad = padding_traj_nn(traj_ang_pad)
        # pad vel, fill zeros
        traj_vel_pad = np.full((len(ts), 2), 0.0)
        traj_vel_pad[traj_ts] = traj_vel

        trajs_pos.append(traj_pos_pad)
        trajs_ang.append(traj_ang_pad)
        trajs_vel.append(traj_vel_pad)
        trajs_type.append(traj_type)
        has_flags.append(has_flag)
        trajs_tid.append(sorted_tid[k])
        trajs_cat.append(sorted_cat[k])

    
    trajs_pos = np.array(trajs_pos).astype(np.float32)  # [N, 110(50), 2]
    trajs_ang = np.array(trajs_ang).astype(np.float32)  # [N, 110(50)]
    trajs_vel = np.array(trajs_vel).astype(np.float32)  # [N, 110(50), 2]
    trajs_type = np.array(trajs_type).astype(np.int16)  # [N, 110(50), 7]
    has_flags = np.array(has_flags).astype(np.int16)  # [N, 110(50)]
    
    # Convert to Tensor first
    trajs_pos = torch.from_numpy(trajs_pos).to(device)
    trajs_ang = torch.from_numpy(trajs_ang).to(device)
    trajs_vel = torch.from_numpy(trajs_vel).to(device)
    trajs_type = torch.from_numpy(trajs_type).to(device)
    has_flags = torch.from_numpy(has_flags).to(device)

    return (trajs_pos, trajs_ang, trajs_vel, trajs_type, has_flags, trajs_tid, trajs_cat)


def update_lane_graph_from_argo(static_map, orig, rot):
    node_ctrs, node_vecs, lane_type, intersect, cross_left, cross_right, left, right = [], [], [], [], [], [], [], []
    lane_ctrs, lane_vecs = [], []
    NUM_SEG_POINTS = 10
    SEG_LENGTH = 15.0

    for lane_id, lane in static_map.vector_lane_segments.items():
        # get lane centerline
        cl_raw = static_map.get_lane_segment_centerline(lane_id)[:, 0:2]  # use xy
        assert cl_raw.shape[0] == NUM_SEG_POINTS, "[Error] Wrong num of points in lane - {}:{}".format(
            lane_id, cl_raw.shape[0])

        cl_ls = LineString(cl_raw)
        num_segs = np.max([int(np.floor(cl_ls.length / SEG_LENGTH)), 1])
        ds = cl_ls.length / num_segs

        for i in range(num_segs):
            s_lb = i * ds
            s_ub = (i + 1) * ds
            num_sub_segs = NUM_SEG_POINTS

            cl_pts = []
            for s in np.linspace(s_lb, s_ub, num_sub_segs + 1):
                cl_pts.append(cl_ls.interpolate(s))
            ctrln = np.array(LineString(cl_pts).coords)  # [num_sub_segs + 1, 2]
            ctrln = (ctrln - orig).dot(rot)  # to local frame

            anch_pos = np.mean(ctrln, axis=0)
            anch_vec = (ctrln[-1] - ctrln[0]) / np.linalg.norm(ctrln[-1] - ctrln[0])
            anch_rot = np.array([[anch_vec[0], -anch_vec[1]],
                                 [anch_vec[1], anch_vec[0]]])

            lane_ctrs.append(anch_pos)
            lane_vecs.append(anch_vec)

            ctrln = (ctrln - anch_pos).dot(anch_rot)  # to instance frame

            ctrs = np.asarray((ctrln[:-1] + ctrln[1:]) / 2.0, np.float32)
            vecs = np.asarray(ctrln[1:] - ctrln[:-1], np.float32)
            node_ctrs.append(ctrs)  # middle point
            node_vecs.append(vecs)

            # ~ lane type
            lane_type_tmp = np.zeros(3)
            if lane.lane_type == LaneType.VEHICLE:
                lane_type_tmp[0] = 1
            elif lane.lane_type == LaneType.BIKE:
                lane_type_tmp[1] = 1
            elif lane.lane_type == LaneType.BUS:
                lane_type_tmp[2] = 1
            else:
                assert False, "[Error] Wrong lane type"
            lane_type.append(np.expand_dims(lane_type_tmp, axis=0).repeat(num_sub_segs, axis=0))

            # ~ intersection
            if lane.is_intersection:
                intersect.append(np.ones(num_sub_segs, np.float32))
            else:
                intersect.append(np.zeros(num_sub_segs, np.float32))

            # ~ lane marker type
            cross_left_tmp = np.zeros(3)
            if lane.left_mark_type in [LaneMarkType.DASH_SOLID_YELLOW,
                                       LaneMarkType.DASH_SOLID_WHITE,
                                       LaneMarkType.DASHED_WHITE,
                                       LaneMarkType.DASHED_YELLOW,
                                       LaneMarkType.DOUBLE_DASH_YELLOW,
                                       LaneMarkType.DOUBLE_DASH_WHITE]:
                cross_left_tmp[0] = 1  # crossable
            elif lane.left_mark_type in [LaneMarkType.DOUBLE_SOLID_YELLOW,
                                         LaneMarkType.DOUBLE_SOLID_WHITE,
                                         LaneMarkType.SOLID_YELLOW,
                                         LaneMarkType.SOLID_WHITE,
                                         LaneMarkType.SOLID_DASH_WHITE,
                                         LaneMarkType.SOLID_DASH_YELLOW,
                                         LaneMarkType.SOLID_BLUE]:
                cross_left_tmp[1] = 1  # not crossable
            else:
                cross_left_tmp[2] = 1  # unknown/none

            cross_right_tmp = np.zeros(3)
            if lane.right_mark_type in [LaneMarkType.DASH_SOLID_YELLOW,
                                        LaneMarkType.DASH_SOLID_WHITE,
                                        LaneMarkType.DASHED_WHITE,
                                        LaneMarkType.DASHED_YELLOW,
                                        LaneMarkType.DOUBLE_DASH_YELLOW,
                                        LaneMarkType.DOUBLE_DASH_WHITE]:
                cross_right_tmp[0] = 1  # crossable
            elif lane.right_mark_type in [LaneMarkType.DOUBLE_SOLID_YELLOW,
                                          LaneMarkType.DOUBLE_SOLID_WHITE,
                                          LaneMarkType.SOLID_YELLOW,
                                          LaneMarkType.SOLID_WHITE,
                                          LaneMarkType.SOLID_DASH_WHITE,
                                          LaneMarkType.SOLID_DASH_YELLOW,
                                          LaneMarkType.SOLID_BLUE]:
                cross_right_tmp[1] = 1  # not crossable
            else:
                cross_right_tmp[2] = 1  # unknown/none

            cross_left.append(np.expand_dims(cross_left_tmp, axis=0).repeat(num_sub_segs, axis=0))
            cross_right.append(np.expand_dims(cross_right_tmp, axis=0).repeat(num_sub_segs, axis=0))

            # ~ has left/right neighbor
            if lane.left_neighbor_id is None:
                left.append(np.zeros(num_sub_segs, np.float32))  # w/o left neighbor
            else:
                left.append(np.ones(num_sub_segs, np.float32))
            if lane.right_neighbor_id is None:
                right.append(np.zeros(num_sub_segs, np.float32))  # w/o right neighbor
            else:
                right.append(np.ones(num_sub_segs, np.float32))

    node_idcs = []  # List of range
    count = 0
    for i, ctr in enumerate(node_ctrs):
        node_idcs.append(range(count, count + len(ctr)))
        count += len(ctr)

    lane_idcs = []  # node belongs to which lane, e.g. [0   0   0 ... 122 122 122]
    for i, idcs in enumerate(node_idcs):
        lane_idcs.append(i * np.ones(len(idcs), np.int16))
    # print("lane_idcs: ", lane_idcs.shape, lane_idcs)

    graph = dict()
    # geometry
    graph['node_ctrs'] = np.stack(node_ctrs, axis=0).astype(np.float32)
    graph['node_vecs'] = np.stack(node_vecs, axis=0).astype(np.float32)
    graph['lane_ctrs'] = np.array(lane_ctrs).astype(np.float32)
    graph['lane_vecs'] = np.array(lane_vecs).astype(np.float32)
    # node features
    graph['lane_type'] = np.stack(lane_type, axis=0).astype(np.int16)
    graph['intersect'] = np.stack(intersect, axis=0).astype(np.int16)
    graph['cross_left'] = np.stack(cross_left, axis=0).astype(np.int16)
    graph['cross_right'] = np.stack(cross_right, axis=0).astype(np.int16)
    graph['left'] = np.stack(left, axis=0).astype(np.int16)
    graph['right'] = np.stack(right, axis=0).astype(np.int16)
    graph['num_nodes'] = graph['node_ctrs'].shape[0] * graph['node_ctrs'].shape[1]
    graph['num_lanes'] = graph['lane_ctrs'].shape[0]
    return graph


def get_closest_point_on_segment(segment, point):
    p1, p2 = segment
    # Vector from p1 to p2
    segment_vector = p2 - p1

    # Projected vector from p1 to p
    projected_vector = torch.dot(point - p1, segment_vector) / torch.dot(segment_vector, segment_vector)

    # Clamp the projection to the segment
    t = torch.clamp(projected_vector, 0, 1)

    # Find the closest point on the segment
    closest = p1 + t * segment_vector
    return closest


def get_distance_to_polyline(polyline, point):
    min_distance = None

    for i in range(len(polyline) - 1):
        segment = (polyline[i], polyline[i + 1])
        closest = get_closest_point_on_segment(segment, point)
        distance = torch.norm(closest - point)

        if min_distance is None or distance < min_distance:
            min_distance = distance

    return min_distance


def get_covariance_matrix(data):
    # check is torch or numpy
    if isinstance(data, torch.Tensor):
        ret_shape = data.shape[:-1] + (2, 2)
        sigma_x = data[..., 0]
        sigma_y = data[..., 1]
        rho = data[..., 2]
        sigma_xy = rho * sigma_x * sigma_y
        return torch.stack([sigma_x ** 2, sigma_xy, sigma_xy, sigma_y ** 2], dim=-1).view(ret_shape)
    elif isinstance(data, np.ndarray):
        ret_shape = data.shape[:-1] + (2, 2)
        sigma_x = data[..., 0]
        sigma_y = data[..., 1]
        rho = data[..., 2]
        sigma_xy = rho * sigma_x * sigma_y
        return np.stack([sigma_x ** 2, sigma_xy, sigma_xy, sigma_y ** 2], axis=-1).reshape(ret_shape)
    else:
        raise ValueError("data should be torch.Tensor or numpy.ndarray")


def get_max_covariance(data):
    # check is torch or numpy
    if isinstance(data, torch.Tensor):
        ret_shape = data.shape[:-1] + (1,)
        sigma_x = data[..., 0]
        sigma_y = data[..., 1]
        # only return the maximum sigma
        return torch.maximum(sigma_x, sigma_y).view(ret_shape)
    elif isinstance(data, np.ndarray):
        ret_shape = data.shape[:-1] + (1,)
        sigma_x = data[..., 0]
        sigma_y = data[..., 1]
        # only return the maximum sigma
        return np.maximum(sigma_x, sigma_y).reshape(ret_shape)
    else:
        raise ValueError("data should be torch.Tensor or numpy.ndarray")


def calculate_adaptive_corridor(lane_width, road_width, ego_vel):
    """
    åŸºäºè·¯å®½å’Œè½¦é€ŸåŠ¨æ€è®¡ç®—åŒå±‚èµ°å»Šè¾¹ç•Œ
    [ä¿®æ­£ç‰ˆ] æ·»åŠ å‡ ä½•çº¦æŸé’³ä½ (Geometric Clamping)
    
    Args:
        lane_width: å½“å‰è½¦é“å®½åº¦ (m)
        road_width: é“è·¯æ€»å®½åº¦ (m)ï¼ŒåŒ…æ‹¬ç›¸é‚»è½¦é“
        ego_vel: è‡ªè½¦é€Ÿåº¦ (m/s)
    
    Returns:
        d_critical: å†…å±‚è¾¹ç•Œï¼ˆç»å¯¹ç¦åŒºï¼‰
        d_outer: å¤–å±‚è¾¹ç•Œï¼ˆæ„ŸçŸ¥èŒƒå›´ï¼‰
    """
    EGO_WIDTH = 2.0
    SAFETY_MARGIN = 0.2  # å®‰å…¨ä½™é‡
    
    # ====== å†…å±‚ (d_critical) - å‡ ä½•çº¦æŸé’³ä½ ======
    # 1. åŠ¨åŠ›å­¦éœ€æ±‚ï¼šåŸºç¡€ 0.5m + é€Ÿåº¦ç¼“å†²
    dynamic_need = 0.5 + 0.03 * abs(ego_vel)
    
    # 2. å‡ ä½•çº¦æŸï¼šå†…å±‚å®½åº¦ç»ä¸èƒ½è¶…è¿‡ (è½¦é“å®½/2 - 0.2m)
    geometric_limit = (lane_width / 2.0) - SAFETY_MARGIN
    
    # 3. å–ä¸¤è€…è¾ƒå°å€¼ (å…³é”®é’³ä½)
    d_critical = min(dynamic_need, geometric_limit)
    d_critical = max(d_critical, 0.2)  # å…œåº•
    
    # ====== å¤–å±‚ (d_outer) - ç‰©ç†è¾¹ç•Œçº¦æŸ ======
    # å¤–å±‚å®½åº¦ç»ä¸èƒ½è¶…è¿‡é“è·¯ç‰©ç†è¾¹ç•Œ
    physical_boundary = road_width / 2.0
    d_outer = min(7.0, physical_boundary)  # [Fix] æŠŠ 5.0 æå‡åˆ° 7.0
    
    # ç¡®ä¿å¤–å±‚ > å†…å±‚
    d_outer = max(d_outer, d_critical + 0.5)
    
    return d_critical, d_outer


def is_obstacle_on_target_lane(obs_pos, target_lane, lane_width=3.5):
    """
    æ£€æŸ¥éšœç¢ç‰©æ˜¯å¦åœ¨ç›®æ ‡è½¦é“ä¸Šæˆ–é™„è¿‘
    
    Args:
        obs_pos: éšœç¢ç‰©ä½ç½® [x, y] (numpy array)
        target_lane: ç›®æ ‡è½¦é“ä¸­å¿ƒçº¿ [N, 2] (numpy array)
        lane_width: è½¦é“å®½åº¦ (m)
    
    Returns:
        bool: True å¦‚æœéšœç¢ç‰©å¯èƒ½é˜»æŒ¡ Ego
    """
    if target_lane is None or len(target_lane) == 0:
        return True  # æ— ç›®æ ‡è½¦é“ä¿¡æ¯æ—¶é»˜è®¤ä¸è¿‡æ»¤
    
    # è®¡ç®—éšœç¢ç‰©åˆ°è½¦é“ä¸­å¿ƒçº¿çš„æœ€çŸ­è·ç¦»
    dists = np.linalg.norm(target_lane - obs_pos, axis=1)
    min_dist = np.min(dists)
    
    # å¦‚æœè·ç¦» > è½¦é“å®½åº¦çš„ä¸€åŠ + ä½™é‡ï¼Œè¯´æ˜ä¸åœ¨ç›®æ ‡è½¦é“ä¸Š
    # å¦‚æœè·ç¦» > è½¦é“å®½åº¦çš„ä¸€åŠ + ä½™é‡ï¼Œè¯´æ˜ä¸åœ¨ç›®æ ‡è½¦é“ä¸Š
    # ä¿®æ­£ï¼šå¯¹äºé¬¼æ¢å¤´æ£€æµ‹ï¼Œæˆ‘ä»¬éœ€è¦å…³æ³¨è·¯è¾¹çš„é®æŒ¡ç‰©
    # åŸæ¥æ˜¯ (lane_width / 2.0) + 0.5 (çº¦ 2.25m)
    # ä¿®æ­£ï¼šå¯¹äºé¬¼æ¢å¤´æ£€æµ‹ï¼Œæˆ‘ä»¬éœ€è¦å…³æ³¨è·¯è¾¹çš„é®æŒ¡ç‰©
    threshold = (lane_width / 2.0) + 4.5  # [Fix] æ‰©å¤§æ£€æµ‹èŒƒå›´ï¼Œæ•è·è·¯è¾¹å¤§å·´
    
    return min_dist < threshold


def project_to_lateral_distance(ego_pos, ghost_point, lane_heading):
    """
    è®¡ç®—æ¨ªå‘è·ç¦»ï¼ˆç”¨äº KA-RF Sigmoid è®¡ç®—ï¼‰
    
    Args:
        ego_pos: è‡ªè½¦ä½ç½® [x, y]
        ghost_point: é£é™©ç‚¹ä½ç½® [x, y]
        lane_heading: è½¦é“æ–¹å‘è§’ (rad)
    
    Returns:
        float: æ¨ªå‘è·ç¦» (m)
    """
    dx = ego_pos[0] - ghost_point[0]
    dy = ego_pos[1] - ghost_point[1]
    
    # æŠ•å½±åˆ°æ¨ªå‘å¹³é¢
    sin_h = np.sin(lane_heading)
    cos_h = np.cos(lane_heading)
    
    lateral_dist = abs(-dx * sin_h + dy * cos_h)
    
    return lateral_dist


def is_separated_by_solid_line(obs_pos, ego_pos, ego_heading, lane_mark_type):
    """
    æ£€æŸ¥éšœç¢ç‰©å’Œ Ego ä¹‹é—´æ˜¯å¦æœ‰ä¸å¯è·¨è¶Šçš„åˆ†éš”çº¿
    
    Args:
        obs_pos: éšœç¢ç‰©ä½ç½® [x, y]
        ego_pos: Ego ä½ç½® [x, y]
        ego_heading: Ego èˆªå‘è§’ (rad)
        lane_mark_type: è½¦é“çº¿ç±»å‹å‘é‡ [crossable, not_crossable, unknown]
    
    Returns:
        bool: True å¦‚æœè¢«å®çº¿/åŒé»„çº¿åˆ†éš”ï¼ˆåº”è¯¥è¿‡æ»¤ï¼‰
    """
    # åˆ¤æ–­éšœç¢ç‰©åœ¨ Ego çš„å·¦è¾¹è¿˜æ˜¯å³è¾¹
    vec_to_obs = obs_pos - ego_pos
    ego_forward = np.array([np.cos(ego_heading), np.sin(ego_heading)])
    
    # å‰ç§¯åˆ¤æ–­å·¦å³
    cross = ego_forward[0] * vec_to_obs[1] - ego_forward[1] * vec_to_obs[0]
    
    # æ£€æŸ¥è½¦é“çº¿æ˜¯å¦ä¸å¯è·¨è¶Š (lane_mark_type[1] == 1 è¡¨ç¤ºå®çº¿)
    if lane_mark_type is not None and len(lane_mark_type) >= 2:
        is_solid = lane_mark_type[1] > 0.5  # ä¸å¯è·¨è¶Š
        if is_solid:
            return True  # è¢«å®çº¿åˆ†éš”ï¼Œåº”è¯¥è¿‡æ»¤
    
    return False


def calculate_phantom_behavior(longitudinal_dist, lateral_dist, ego_vel):
    """
    ã€ä¿®æ­£ç‰ˆã€‘åŸºäº TTA å’Œç‰©ç†å¯è¾¾æ€§çš„å¹»å½±çŠ¶æ€æœº
    
    ä¿®æ­£è¦ç‚¹ï¼š
    1. äººç±»é€Ÿåº¦æ”¹å› 5.0 m/s (åˆç†å†²åˆºé€Ÿåº¦)
    2. å¢åŠ ç‰©ç†å¯è¾¾æ€§æ£€æŸ¥ï¼šé¬¼éœ€è¦è·‘å¤šå¿«æ‰èƒ½æ’ä¸Šï¼Ÿ
    3. å¦‚æœæ‰€éœ€é€Ÿåº¦ > äººç±»æé™ï¼Œåˆ™æ— éœ€å¹»å½±
    
    Args:
        longitudinal_dist: çºµå‘è·ç¦» (m)
        lateral_dist: æ¨ªå‘è·ç¦» (m)
        ego_vel: è‡ªè½¦é€Ÿåº¦ (m/s)
    
    Returns:
        dict: å¹»å½±çŠ¶æ€å’Œç›¸å…³ä¿¡æ¯
    """
    # ã€ä¿®æ­£ã€‘äººç±»å†²åˆºé€Ÿåº¦ 5.0 m/s (18 km/hï¼Œåˆç†ä¸Šé™)
    HUMAN_MAX_SPEED = 5.0
    
    # [PA-LOI Fix] ç¼©çŸ­å‰ç»æ—¶é—´ï¼Œé˜²æ­¢è¿‡æ—©è§¦å‘ BRAKE çŠ¶æ€
    # åŸå€¼ 3.0 -> æ”¹ä¸º 1.5 (é…åˆ Experiment A/v23 çš„æé™æµ‹è¯•)
    LOOKAHEAD_TIME = 1.5  # ç§’ (Critical Reaction Time)
    
    result = {
        'state': 'OBSERVE',
        'inject_phantom': False,
        'risk_field_only': True,
        'safe_to_pass': False,
        'tta_ego': float('inf'),
        'tta_human': float('inf'),
        'v_required': 0.0  # é¬¼éœ€è¦çš„é€Ÿåº¦
    }
    
    # è®¡ç®— TTA
    if ego_vel > 0.1:
        result['tta_ego'] = longitudinal_dist / ego_vel
    if lateral_dist > 0.1:
        result['tta_human'] = lateral_dist / HUMAN_MAX_SPEED
    
    tta_ego = result['tta_ego']
    tta_human = result['tta_human']
    
    # ã€å…³é”®ä¿®æ­£ã€‘ç‰©ç†å¯è¾¾æ€§æ£€æŸ¥
    # é¬¼éœ€è¦è·‘å¤šå¿«æ‰èƒ½åœ¨ Ego åˆ°è¾¾å‰æ‹¦ä½ Egoï¼Ÿ
    if tta_ego > 0.01:
        v_required = lateral_dist / tta_ego
        result['v_required'] = v_required
    else:
        v_required = float('inf')
    
    # å®‰å…¨é€šè¿‡æ¡ä»¶
    result['safe_to_pass'] = tta_ego < tta_human
    
    # ====== ä¿®æ­£åçš„çŠ¶æ€æœº ======
    
    # ç‰©ç†å¯è¾¾æ€§æ£€æŸ¥ï¼šå¦‚æœé¬¼è·‘æ–­è…¿ä¹Ÿæ’ä¸ä¸Šï¼Œæ— éœ€å¹»å½±
    if v_required > HUMAN_MAX_SPEED:
        result['state'] = 'OBSERVE'
        result['inject_phantom'] = False
        result['risk_field_only'] = True
    
    # è·ç¦»æ£€æŸ¥ï¼šå¤ªè¿œä¹Ÿæ— éœ€å¹»å½±
    elif tta_ego > LOOKAHEAD_TIME:
        result['state'] = 'OBSERVE'
        result['inject_phantom'] = False
        result['risk_field_only'] = True
    
    # æ—¢è¿‘ï¼Œåˆèƒ½æ’ä¸Š -> å¿…é¡»å¤„ç†
    else:
        result['state'] = 'BRAKE'
        result['inject_phantom'] = True
        result['risk_field_only'] = False
    
    return result


def get_semantic_risk_sources(trajs_pos, trajs_vel, trajs_type, trajs_ang, ego_pos, ego_heading, 
                                device='cpu', ego_vel=None, lane_width=3.5, road_width=None,
                                target_lane=None):
    """
    [PA-LOI å‡çº§ç‰ˆ] è¯†åˆ«è¯­ä¹‰çº§é£é™©æºï¼ˆé¬¼æ¢å¤´åŒºåŸŸï¼‰
    
    å¢å¼ºåŠŸèƒ½ï¼š
    1. åŠ¨æ€åŒå±‚èµ°å»Šï¼ˆåŸºäºè·¯å®½å’Œè½¦é€Ÿï¼‰
    2. TTA çŠ¶æ€æœºï¼ˆåŸºäºæ—¶é—´è€Œéå›ºå®šè·ç¦»ï¼‰
    3. ç›®æ ‡è½¦é“ç­›é€‰
    
    Args:
        trajs_pos: [N, T, 2] æ‰€æœ‰æ™ºèƒ½ä½“ä½ç½®è½¨è¿¹
        trajs_vel: [N, T, 2] æ‰€æœ‰æ™ºèƒ½ä½“é€Ÿåº¦è½¨è¿¹
        trajs_type: [N, T, type_dim] ç±»å‹ one-hot
        trajs_ang: [N, T] èˆªå‘è§’
        ego_pos: [2] Ego å½“å‰ä½ç½®
        ego_heading: scalar Ego å½“å‰èˆªå‘
        device: torch device
        ego_vel: scalar Ego å½“å‰é€Ÿåº¦ (m/s)ï¼Œç”¨äº TTA å’ŒåŠ¨æ€èµ°å»Šè®¡ç®—
        lane_width: float å½“å‰è½¦é“å®½åº¦ (m)
        road_width: float é“è·¯æ€»å®½åº¦ (m)ï¼Œé»˜è®¤ä½¿ç”¨ lane_width
        target_lane: [M, 2] ç›®æ ‡è½¦é“ä¸­å¿ƒçº¿ï¼Œç”¨äºç­›é€‰
    
    Returns:
        List of risk dictionaries with 'pos', 'cov', 'weight', 'phantom_state'
    """
    risk_sources = []
    filter_log = []
    
    # é»˜è®¤é€Ÿåº¦
    if ego_vel is None:
        ego_vel = 5.0  # é»˜è®¤ 5 m/s
    if road_width is None:
        road_width = lane_width
    
    # ====== PA-LOI æ ¸å¿ƒï¼šåŠ¨æ€èµ°å»Šè®¡ç®— ======
    d_critical, d_outer = calculate_adaptive_corridor(lane_width, road_width, ego_vel)
    print(f"[PA-LOI] Dynamic Corridor: d_critical={d_critical:.2f}m, d_outer={d_outer:.2f}m (lane={lane_width:.1f}m, v={ego_vel:.1f}m/s)")
    
    # å°ºå¯¸ä¼°ç®— (åŠé•¿, åŠå®½)
    DIMENSIONS = {
        'BUS': (6.0, 1.5),
        'VEHICLE': (2.5, 1.0),
    }
    
    STATIC_SPEED_THRES = 0.5  # m/s
    MAX_LONGITUDINAL = 50.0   # æ‰©å±•æ£€æµ‹èŒƒå›´åˆ° 50m
    
    curr_step = -1
    num_agents = len(trajs_pos)
    
    if ego_pos is None:
        ego_pos = trajs_pos[0, curr_step]
    if ego_heading is None:
        ego_heading = trajs_ang[0, curr_step]
    
    ego_forward = torch.stack([torch.cos(ego_heading), torch.sin(ego_heading)])
    
    for i in range(num_agents):
        if i == 0:
            continue
        
        agent_log = {'agent_idx': i, 'passed': False, 'reject_reason': None}
        
        # --- ç±»å‹ç­›é€‰ ---
        agent_type_vec = trajs_type[i, curr_step]
        
        is_occluder = False
        half_len, half_width = 2.5, 1.0
        agent_type_str = 'UNKNOWN'
        
        if agent_type_vec[4] == 1:  # BUS
            is_occluder = True
            half_len, half_width = DIMENSIONS['BUS']
            agent_type_str = 'BUS'
        elif agent_type_vec[0] == 1:  # Vehicle
            is_occluder = True
            half_len, half_width = DIMENSIONS['VEHICLE']
            agent_type_str = 'VEHICLE'
        
        agent_log['type'] = agent_type_str
        
        if not is_occluder:
            agent_log['reject_reason'] = 'NOT_OCCLUDER_TYPE'
            continue
        
        # --- é€Ÿåº¦ç­›é€‰ ---
        vel = trajs_vel[i, curr_step]
        speed = torch.norm(vel).item()
        agent_log['speed'] = speed
        
        if speed > STATIC_SPEED_THRES:
            agent_log['reject_reason'] = f'MOVING (speed={speed:.2f}m/s)'
            continue
        
        # --- ä½ç½®è®¡ç®— ---
        obs_pos = trajs_pos[i, curr_step]
        vec_to_obs = obs_pos - ego_pos
        
        longitudinal = torch.dot(vec_to_obs, ego_forward).item()
        lateral = torch.abs(ego_forward[0] * vec_to_obs[1] - ego_forward[1] * vec_to_obs[0]).item()
        
        agent_log['pos'] = obs_pos.cpu().numpy().tolist()
        agent_log['longitudinal'] = longitudinal
        agent_log['lateral'] = lateral
        
        # --- çºµå‘ç­›é€‰ ---
        # ä¿®æ­£ï¼šä¸ºäº†é˜²æ­¢æ¼æ‰åˆšç»è¿‡è½¦å¤´çš„é•¿è½¦(å…¬äº¤)ï¼Œå…è®¸ä¸€å®šçš„è´Ÿå€¼
        if longitudinal < -5.0:
            agent_log['reject_reason'] = f'BEHIND_EGO (long={longitudinal:.2f}m)'
            filter_log.append(agent_log)
            continue
            
        if longitudinal > MAX_LONGITUDINAL:
            agent_log['reject_reason'] = f'TOO_FAR (long={longitudinal:.2f}m > {MAX_LONGITUDINAL}m)'
            filter_log.append(agent_log)
            continue
        
        # --- PA-LOI: åŠ¨æ€èµ°å»Šç­›é€‰ï¼ˆä½¿ç”¨ d_outer è€Œéå›ºå®šå€¼ï¼‰---
        if lateral > d_outer:
            agent_log['reject_reason'] = f'OUT_OF_CORRIDOR (lat={lateral:.2f}m > d_outer={d_outer:.2f}m)'
            filter_log.append(agent_log)
            continue
        
        # --- PA-LOI: ç›®æ ‡è½¦é“ç­›é€‰ ---
        # æ³¨æ„ï¼šthreshold å·²æ”¾å®½åˆ° (lane_width/2) + 2.5
        if target_lane is not None:
            if not is_obstacle_on_target_lane(obs_pos.cpu().numpy(), target_lane, lane_width):
                agent_log['reject_reason'] = f'NOT_ON_TARGET_LANE'
                filter_log.append(agent_log)  # è®°å½•è¢«æ‹’ç»çš„åŸå› 
                continue
        
        # === PASSED ALL FILTERS ===
        agent_log['passed'] = True
        agent_log['reject_reason'] = None
        filter_log.append(agent_log)
        
        # --- è®¡ç®—è§’ç‚¹å’Œå±é™©ç‚¹ ---
        obs_ang = trajs_ang[i, curr_step]
        
        cos_a = torch.cos(obs_ang)
        sin_a = torch.sin(obs_ang)
        
        corners_local = torch.tensor([
            [ half_len,  -half_width],
            [ half_len,   half_width],
            [-half_len,   half_width],
            [-half_len,  -half_width],
        ], device=device, dtype=torch.float32)
        
        rot_matrix = torch.tensor([
            [cos_a, -sin_a],
            [sin_a,  cos_a]
        ], device=device, dtype=torch.float32)
        
        corners_global = torch.mm(corners_local, rot_matrix.T) + obs_pos
        
        # --- è§†çº¿åˆ‡ç‚¹ç®—æ³• ---
        vecs_to_corners = corners_global - ego_pos
        angles_to_corners = torch.atan2(vecs_to_corners[:, 1], vecs_to_corners[:, 0])
        angle_ego = torch.atan2(ego_forward[1], ego_forward[0])
        
        relative_angles = angles_to_corners - angle_ego
        relative_angles = torch.atan2(torch.sin(relative_angles), torch.cos(relative_angles))
        
        left_tangent_idx = torch.argmax(relative_angles)
        right_tangent_idx = torch.argmin(relative_angles)
        
        vec_to_obs_center = obs_pos - ego_pos
        cross = ego_forward[0] * vec_to_obs_center[1] - ego_forward[1] * vec_to_obs_center[0]
        
        if cross > 0:
            ghost_point = corners_global[right_tangent_idx]
        else:
            ghost_point = corners_global[left_tangent_idx]
        
        # --- æ£€æŸ¥å±é™©ç‚¹ ---
        vec_to_ghost = ghost_point - ego_pos
        proj_forward = torch.dot(vec_to_ghost, ego_forward)
        
        if proj_forward < 0:
            for log in filter_log:
                if log['agent_idx'] == i and log['passed']:
                    log['passed'] = False
                    log['reject_reason'] = 'GHOST_POINT_BEHIND'
            continue
        
        # --- PA-LOI: Ghost Point ä½¿ç”¨åŠ¨æ€èµ°å»Šç­›é€‰ ---
        ghost_lateral = torch.abs(ego_forward[0] * vec_to_ghost[1] - ego_forward[1] * vec_to_ghost[0]).item()
        ghost_longitudinal = proj_forward.item()
        
        # ä½¿ç”¨ d_outer ä½œä¸ºé˜ˆå€¼ï¼ˆåŠ¨æ€èµ°å»Šå¤–è¾¹ç•Œï¼‰
        # ä¿®æ­£ï¼šåŸæ¥ä½¿ç”¨ d_critical + 0.5 (çº¦1.1m)ï¼Œå¯¹äºè·¯è¾¹åœè½¦åœºæ™¯å¤ªå°
        ghost_threshold = d_outer
        if ghost_lateral > ghost_threshold:
            for log in filter_log:
                if log['agent_idx'] == i and log['passed']:
                    log['passed'] = False
                    log['reject_reason'] = f'GHOST_LATERAL_TOO_FAR (lat={ghost_lateral:.2f}m > {ghost_threshold:.2f}m)'
            continue
        
        # ====== PA-LOI æ ¸å¿ƒï¼šTTA çŠ¶æ€æœº ======
        phantom_result = calculate_phantom_behavior(ghost_longitudinal, ghost_lateral, ego_vel)
        
        # ============================================================
        # [PA-LOI v52] Hinge-Loss è™šå®åŒè½¨ç­–ç•¥ (Final Fix)
        # ============================================================
        # æ ¸å¿ƒæ”¹åŠ¨ï¼šå¼•å…¥ v_safe (å®‰å…¨é˜²å«é€Ÿåº¦)
        # é…åˆ potential.py ä¸­çš„ max(0, v - v_safe)^2 
        #
        # 1. è™šæ‹Ÿé£é™© (Blind Spot):
        #    v_safe = 2.5 m/s. æ„å›¾ï¼šä»…æ”¶æ²¹è‡³é˜²å«é€Ÿåº¦ï¼Œå…è®¸é€šè¿‡ã€‚
        #    Optimize: è½¦è¾†å¹³æ»‘å‡é€Ÿè‡³ 2.5 åä¸å†å‡é€Ÿ (Cost=0 by Hinge Loss)
        #
        # 2. çœŸå®é£é™© (Real Obstacle):
        #    v_safe = 0.0 m/s. æ„å›¾ï¼šå¿…é¡»åˆ¹åœã€‚
        #    Optimize: ä¸€è„šè·ºæ­»
        # ============================================================
        
        # ============================================================
        # [PA-LOI v53 Final] çº¯ç²¹çš„é˜²å«æ€§é£é™©åœº
        # çœŸå®éšœç¢ç‰©äº¤ç”± planner.py çš„ AEB æ¨¡å—å¤„ç†ã€‚
        # è¿™é‡Œçš„è™šæ‹ŸåŠ¿åœºåªè´Ÿè´£ä¸€ä»¶äº‹ï¼šè®©è½¦è¾†é€¼è¿‘ç›²åŒºæ—¶ï¼Œå°†é€Ÿåº¦å¹³æ»‘å‹åˆ¶åˆ° 2.5m/sã€‚
        # ============================================================
        v_safe = 2.5  # æ°¸è¿œä¿æŒ 2.5m/s çš„å®‰å…¨é˜²å«é€Ÿåº¦
        
        # [Fix] è¡¥å›è¢«è¯¯åˆ çš„å˜é‡å®šä¹‰
        tta_ego = phantom_result['tta_ego']
        
        if tta_ego > 5.0:       
            weight = 0.0        # 5ç§’å¤–ï¼šè‡ªç”±é©¾é©¶ï¼Œæ— è§†ç›²åŒº
        elif tta_ego > 2.0:     
            # 5s -> 2sï¼šæƒé‡çº¿æ€§å¢åŠ  (0 -> 15)ï¼Œäº§ç”Ÿå¹³æ»‘å‡é€Ÿæ¢¯åº¦
            weight = 15.0 * (5.0 - tta_ego) / 3.0
        else:                   
            # < 2sï¼šè´´è¿‘ç›²åŒºï¼Œæƒé‡å°é¡¶ã€‚
            # æ­¤æ—¶è‹¥è½¦é€Ÿé™è‡³ 2.5m/sï¼ŒåŠ¿åœº Hinge-Loss æ¢¯åº¦å½’é›¶ï¼Œè½¦è¾†åŒ€é€Ÿæºœè¿‡è·¯å£ï¼
            weight = 15.0
        
        # --- æ ‡å‡†åæ–¹å·® (ä»…å½±å“ evaluate_traj_tree) ---
        sigma = 0.8
        risk_cov = get_risk_covariance(sigma, device=device)
        
        risk_sources.append({
            'type': 'GHOST_PROBE',
            'pos': ghost_point,
            'cov': risk_cov,
            'weight': weight,
            'v_safe': v_safe,  # [v52] ä¼ é€’ v_safe ç»™ Planner
            'ghost_lateral': ghost_lateral,
            'ghost_longitudinal': ghost_longitudinal,
            # PA-LOI æ–°å¢å­—æ®µ
            'phantom_state': phantom_result['state'],
            'tta_ego': phantom_result['tta_ego'],
            'tta_human': phantom_result['tta_human'],
            'inject_phantom': phantom_result['inject_phantom'],
            'safe_to_pass': phantom_result['safe_to_pass']
        })
    
    # === PRINT FILTER LOG ===
    # passed_count = sum(1 for log in filter_log if log['passed'])
    # if len(filter_log) > 0 or len(risk_sources) > 0:
    #     print(f"[PA-LOI RISK] Candidates: {len(filter_log)} | Passed: {passed_count} | Final: {len(risk_sources)}")
    #     for rs in risk_sources:
    #         state_emoji = {'OBSERVE': 'ğŸ‘€', 'BRAKE': 'ğŸš¨', 'PASS': 'âœ…'}.get(rs['phantom_state'], 'â“')
    #         print(f"  {state_emoji} Agent {rs['agent_idx']}: state={rs['phantom_state']} | "
    #               f"TTA_ego={rs['tta_ego']:.2f}s TTA_human={rs['tta_human']:.2f}s | "
    #               f"weight={rs['weight']:.1f} | phantom={rs['inject_phantom']}")
    
    # # [DEBUG] å¦‚æœæœ‰å€™é€‰è€…ä½†å…¨éƒ¨è¢«æ‹’ç»ï¼Œæ‰“å°æ‹’ç»åŸå› 
    # if len(risk_sources) == 0 and len(filter_log) > 0:
    #     rejected = [log for log in filter_log if not log.get('passed', False)]
    #     if len(rejected) > 0:
    #         print(f"[PA-LOI DEBUG] All candidates rejected! Top 5 reasons:")
    #         for log in rejected[:5]:
    #             print(f"  - Agent {log.get('agent_idx', '?')} ({log.get('type', '?')}): {log.get('reject_reason', 'UNKNOWN')}")
    
    return risk_sources



def get_risk_covariance(sigma, device='cpu'):
    """
    ç”Ÿæˆé£é™©åŒºåŸŸçš„åæ–¹å·®çŸ©é˜µï¼ˆåœ†å½¢åŒºåŸŸï¼‰ã€‚
    
    Args:
        sigma: é£é™©åŒºåŸŸåŠå¾„
        device: torch device
    
    Returns:
        [2, 2] åæ–¹å·®çŸ©é˜µ
    """
    var = sigma ** 2
    cov = torch.tensor([[var, 0.0], [0.0, var]], device=device, dtype=torch.float32)
    return cov

